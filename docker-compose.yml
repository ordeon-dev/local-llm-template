services:
    webui:
        image: ghcr.io/open-webui/open-webui:main
        container_name: webui
        ports:
            - 7001:8080/tcp
        volumes:
            - open-webui:/app/backend/data
        extra_hosts:
            - 'host.docker.internal:host-gateway'
        depends_on:
            - ollama
        restart: unless-stopped

    ollama:
        build: ollama
        ports:
            - 11434:11434
        environment:
            - OLLAMA_MODEL=phi4
            - OLLAMA_NUM_PARALLEL=2
        volumes:
            - ollama:/ollama
        entrypoint: ['/usr/bin/bash', '/pull-model.sh']

    api:
        build: app
        container_name: ollama-api
        ports:
            - 8000:8000
        depends_on:
            - ollama
        volumes:
            - ./app:/app
        environment:
            - OLLAMA_HOST=http://ollama:11434
            - OLLAMA_MODEL=stablelm2
        restart: unless-stopped

volumes:
    ollama:
    open-webui:
